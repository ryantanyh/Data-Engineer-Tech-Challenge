# Data-Engineer-Tech-Challenge

**Section 1**
Airflow is used to implement the scheduling component
A dataprocessing.py containing the codes from the uploaded data engineering tech challenge section 1.ipynb file will be scheduled in airflow at 1am to process the datafiles on a daily basis. 

**Section 3**
A system architecture diagram on Powerpoint shows the system design for processing and storing images. Microsoft Azure Cloud provider is used for this example. The main application used is Azure HDInsights which contains Kafka to stream the images.
